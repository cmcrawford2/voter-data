{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b081547",
   "metadata": {},
   "source": [
    "# voter data project\n",
    "### by Cris Crawford\n",
    "The purpose of this file is to unzip the voter activity file in my Google cloud bucket, convert the resulting data into parquet files, and put the parquet files back into the Google cloud bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe93279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3917628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/cris/.gc/keys.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccb73be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cris/.gc/keys.json\n"
     ]
    }
   ],
   "source": [
    "google_application_credentials = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "print(google_application_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18653c28",
   "metadata": {},
   "source": [
    "### The following cell was run once to unzip the data file.\n",
    "It created 351 files, each holding the information about elections in a particular city or town. All other cells can be run repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d589d664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: <Bucket: cris-voter-data>\n",
      "Blob: <Blob: cris-voter-data, voter_activity_20220828.zip, None>\n",
      "Downloaded zip file to: temp.zip\n",
      "Successfully extracted zip file contents.\n"
     ]
    }
   ],
   "source": [
    "# Initialize GCS client\n",
    "client = storage.Client()\n",
    "\n",
    "# Define GCS bucket and zip file path\n",
    "bucket_name = 'cris-voter-data'\n",
    "zip_file_path = 'voter_activity_20220828.zip'\n",
    "destination_path = 'temp.zip'\n",
    "\n",
    "try:\n",
    "    # Get the bucket\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    print(\"Bucket:\", bucket)\n",
    "\n",
    "    # Get the blob (file) from the bucket\n",
    "    blob = bucket.blob(zip_file_path)\n",
    "    print(\"Blob:\", blob)\n",
    "\n",
    "    # Define the destination path for the downloaded file\n",
    "    destination_path = 'temp.zip'\n",
    "\n",
    "    # Download the blob's content and write it to a file\n",
    "    with open(destination_path, 'wb') as file:\n",
    "        blob.download_to_file(file)\n",
    "    \n",
    "    print(\"Downloaded zip file to:\", destination_path)\n",
    "\n",
    "    # Check if download was successful\n",
    "    if os.path.exists(destination_path):\n",
    "        # Extract the zip file\n",
    "        with zipfile.ZipFile(destination_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('extracted_files')\n",
    "        print(\"Successfully extracted zip file contents.\")\n",
    "    else:\n",
    "        print(\"Failed to download zip file.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c860a64",
   "metadata": {},
   "source": [
    "### Since the data came without columns, I had to define column names, as well as schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5cef27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['election_date', 'election_type', 'voter_id', \\\n",
    "                'tmp1', 'tmp2', 'tmp3', 'tmp4', 'tmp5', 'tmp6', 'tmp7', 'tmp8', \\\n",
    "                'zip', 'city', 'party_affiliation', \\\n",
    "                'tmp9', 'tmp10', \\\n",
    "                'ward', 'precinct', 'voter_status', \\\n",
    "                'tmp11', 'tmp12', 'tmp13', 'tmp14', 'tmp15', 'tmp16']\n",
    "\n",
    "schema = {\n",
    "  'election_date': 'object',\n",
    "  'election_type': 'object',\n",
    "  'voter_id': 'object',\n",
    "  'tmp1': 'object',\n",
    "  'tmp2': 'object',\n",
    "  'tmp3': 'object',\n",
    "  'tmp4': 'object',\n",
    "  'tmp5': 'object',\n",
    "  'tmp6': 'object',\n",
    "  'tmp7': 'object',\n",
    "  'tmp8': 'object',\n",
    "  'zip': 'object',\n",
    "  'city': 'object',\n",
    "  'party_affiliation': 'object',\n",
    "  'tmp9': 'object',\n",
    "  'tmp10 ': 'object',\n",
    "  'ward': 'object',\n",
    "  'precinct': 'object',\n",
    "  'voter_status': 'object',\n",
    "  'tmp11': 'object',\n",
    "  'tmp12': 'object',\n",
    "  'tmp13': 'object',\n",
    "  'tmp14': 'object',\n",
    "  'tmp15': 'object',\n",
    "  'tmp16': 'object'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1677eef",
   "metadata": {},
   "source": [
    "### Here I'm reading one file and checking the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d908a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('extracted_files/001_voter_act.txt', delimiter='|', names=column_names, dtype=schema)\n",
    "df['election_date'] = pd.to_datetime(df['election_date'])\n",
    "df['election_date'] = df['election_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65c3836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows =  237190\n"
     ]
    }
   ],
   "source": [
    "print('n_rows = ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3ac26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest date: 1995-08-22\n"
     ]
    }
   ],
   "source": [
    "earliest_date = df['election_date'].min()\n",
    "\n",
    "print(\"Earliest date:\", earliest_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873abb3c",
   "metadata": {},
   "source": [
    "### Now I define a loop from start number to end number.\n",
    "I read the file and save it with selected columns, write it as parquet, and upload it to my Google cloud bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd9ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "bucket = client.get_bucket('cris-voter-data')\n",
    "\n",
    "selected_columns = ['election_date', 'election_type', 'voter_id', 'zip', 'city', 'party_affiliation', 'ward', 'precinct', 'voter_status']\n",
    "\n",
    "def text_to_parquet(start, end):\n",
    "    for n in range(start, end):\n",
    "        filename = f\"{n:03d}_voter_act.txt\";\n",
    "        df = pd.read_csv('extracted_files/' + filename, delimiter='|', names=column_names, dtype=schema)\n",
    "        new_df = df[selected_columns]\n",
    "        new_df.to_parquet(filename[:-4] + '.parquet', engine='pyarrow')\n",
    "        blob = bucket.blob('output/' + filename[:-4] + '.parquet')\n",
    "        blob.upload_from_filename(filename[:-4] + '.parquet')\n",
    "        print({filename}, len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2acbf5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'340_voter_act.txt'} 53510\n",
      "{'341_voter_act.txt'} 116536\n",
      "{'342_voter_act.txt'} 311957\n",
      "{'343_voter_act.txt'} 112542\n",
      "{'344_voter_act.txt'} 412585\n",
      "{'345_voter_act.txt'} 13006\n",
      "{'346_voter_act.txt'} 312485\n",
      "{'347_voter_act.txt'} 506841\n",
      "{'348_voter_act.txt'} 1441063\n",
      "{'349_voter_act.txt'} 3513\n",
      "{'350_voter_act.txt'} 195544\n",
      "{'351_voter_act.txt'} 410055\n"
     ]
    }
   ],
   "source": [
    "text_to_parquet(340, 352)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef2ddb",
   "metadata": {},
   "source": [
    "### These last cells allow me to read csv files that I created by hand.\n",
    "Several files had bad data in them and could not be read by pandas. I downloaded these files to my computer and opened them in Excel, saved them as .csv files, and uploaded them back to the virtual machine. Then I could proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf34bc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cris/.gc/keys.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/cris/.gc/keys.json'\n",
    "\n",
    "google_application_credentials = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "print(google_application_credentials)\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('cris-voter-data')\n",
    "\n",
    "selected_columns = ['election_date', 'election_type', 'voter_id', 'zip', 'city', 'party_affiliation', 'ward', 'precinct', 'voter_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ac8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(filename):\n",
    "    df = pd.read_csv('extracted_files/' + filename, delimiter=',', names=column_names, dtype=schema)\n",
    "    new_df = df[selected_columns]\n",
    "    new_df.to_parquet(filename[:-4] + '.parquet', engine='pyarrow')\n",
    "    blob = bucket.blob('output/' + filename[:-4] + '.parquet')\n",
    "    blob.upload_from_filename(filename[:-4] + '.parquet')\n",
    "    print(filename, len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ae80c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177_voter_act.csv 136290\n",
      "035c_voter_act.csv 729102\n",
      "049b_voter_act.csv 524179\n",
      "293_voter_act.csv 551527\n",
      "137_voter_act.csv 439518\n",
      "279_voter_act.csv 111978\n",
      "291_voter_act.csv 266369\n",
      "338_voter_act.csv 193082\n",
      "035f_voter_act.csv 709986\n",
      "035d_voter_act.csv 732746\n",
      "258_voter_act.csv 528017\n",
      "072_voter_act.csv 384265\n",
      "035h_voter_act.csv 809793\n",
      "274_voter_act.csv 915640\n",
      "229_voter_act.csv 660342\n",
      "035b_voter_act.csv 732359\n",
      "176_voter_act.csv 741171\n",
      "246_voter_act.csv 439868\n",
      "035g_voter_act.csv 715503\n",
      "289_voter_act.csv 47202\n",
      "035e_voter_act.csv 730499\n",
      "165_voter_act.csv 540971\n",
      "049a_voter_act.csv 599999\n",
      "163_voter_act.csv 752367\n",
      "178_voter_act.csv 458873\n",
      "035a_voter_act.csv 732422\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "directory = 'extracted_files'\n",
    "\n",
    "csv_files = glob.glob(os.path.join(directory, '*.csv'))\n",
    "\n",
    "for file_path in csv_files:\n",
    "    csv_to_parquet(os.path.basename(file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079181b",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89d0a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfe5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
